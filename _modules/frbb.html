<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>frbb &mdash; fast_rboost_bins 0.9.4 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            fast_rboost_bins
          </a>
              <div class="version">
                0.9.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">src</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">fast_rboost_bins</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Module code</a></li>
      <li class="breadcrumb-item active">frbb</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for frbb</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module contains the core machine learning functionalities of the project, embodied by the class `FastRealBoostBins` (compliant with `scikit-learn`).</span>
<span class="sd">The module includes:</span>

<span class="sd">- `FastRealBoostBins`: class representing an ensemble classifier for fast predictions implemented using `numba.jit` and `numba.cuda`,</span>

<span class="sd">- `_lock`, `_unlock`: utility functions (placed outside the class, related to mutex mechanisms in case of numba.cuda-based fit).</span>

<span class="sd">In ``FastRealBoostBins`` class, attributes estimated by the ``fit`` function are named with trailing underscores (e.g. ``features_selected_``, ``logits_``, etc.)</span>
<span class="sd">as indicated in the scikit-learn guidelines. Private functions are named with single leading underscores and some of them are additionally described by </span>
<span class="sd">``@jit`` or ``@cuda.jit`` decorators coming from ``numba`` module (intended to be compiled by `Numba`). </span>

<span class="sd">Documentation note: this documentation was built with `Sphinx` tool, which does not correctly process docstrings for CUDA kernel functions,</span>
<span class="sd">i.e. functions decorated with ``@cuda.jit`` that produce ``numba.cuda.compiler.Dispatcher`` objects as outcomes. </span>
<span class="sd">For actual docstrings associated with those functions see the source code. </span>

<span class="sd">Installation</span>
<span class="sd">------------</span>

<span class="sd">.. code-block:: console</span>
<span class="sd">    </span>
<span class="sd">    pip install frbb</span>
<span class="sd">    </span>
<span class="sd">Note: for further usage, NVIDIA CUDA drivers must be present in the operating system.</span>

<span class="sd">Example Usage</span>
<span class="sd">-------------</span>
<span class="sd">With ``frbb`` module installed, one can write e.g.:</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    from frbb import FastRealBoostBins</span>
<span class="sd">    from sklearn.datasets import load_breast_cancer</span>
<span class="sd">    from sklearn.model_selection import train_test_split    </span>
<span class="sd">    if __name__ == &quot;__main__&quot;:    </span>
<span class="sd">        X, y = load_breast_cancer(return_X_y=True)</span>
<span class="sd">        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=0)</span>
<span class="sd">        clf = FastRealBoostBins()</span>
<span class="sd">        clf.fit(X_train, y_train)</span>
<span class="sd">        print(f&quot;CLF: {clf}&quot;)</span>
<span class="sd">        print(f&quot;TRAIN ACC: {clf.score(X_train, y_train)}&quot;)</span>
<span class="sd">        print(f&quot;TEST ACC: {clf.score(X_test, y_test)}&quot;)</span>

<span class="sd">Running the script above produces the following output:</span>
<span class="sd">        </span>
<span class="sd">.. code-block:: console</span>

<span class="sd">    CLF: FastRealBoostBins(T=256, B=8, outliers_ratio=0.05, logit_max: 2.0, fit_mode=&#39;numba_cuda&#39;, decision_function_mode=&#39;numba_cuda&#39;)</span>
<span class="sd">    TRAIN ACC: 1.0</span>
<span class="sd">    TEST ACC: 0.958041958041958</span>

<span class="sd">Dependencies</span>
<span class="sd">------------</span>
<span class="sd">- ``numpy``, ``math``: required for mathematical computations.</span>

<span class="sd">- ``numba``: required for just-in-time compilation of crucial computational functions and CUDA kernels (decorated by ``@jit`` and ``@cuda.jit`` imported from ``numba``). </span>

<span class="sd">- ``sklearn``: required for inheritence and other sklearn API purposes.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">inf</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span><span class="p">,</span> <span class="n">jit</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">void</span><span class="p">,</span> <span class="n">int8</span><span class="p">,</span> <span class="n">int16</span><span class="p">,</span> <span class="n">int32</span><span class="p">,</span> <span class="n">int64</span><span class="p">,</span> <span class="n">float32</span><span class="p">,</span> <span class="n">float64</span><span class="p">,</span> <span class="n">uint8</span><span class="p">,</span> <span class="n">uint16</span><span class="p">,</span> <span class="n">uint32</span><span class="p">,</span> <span class="n">uint64</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">types</span> <span class="k">as</span> <span class="n">nbtypes</span>
<span class="kn">from</span> <span class="nn">numba.core.errors</span> <span class="kn">import</span> <span class="n">NumbaPerformanceWarning</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">check_X_y</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">column_or_1d</span><span class="p">,</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.multiclass</span> <span class="kn">import</span> <span class="n">check_classification_targets</span>
        
<span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;0.9.4&quot;</span>
<span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Przemysław Klęsk&quot;</span>
<span class="n">__email__</span> <span class="o">=</span> <span class="s2">&quot;pklesk@zut.edu.pl&quot;</span>   
        
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">NumbaPerformanceWarning</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

<span class="c1"># mutex-related cuda utility functions </span>
<span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_lock</span><span class="p">(</span><span class="n">mutex</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Device-side function that locks the wanted critical section (mutex mechanism). Locking means setting the value of variable or array cell (passed by reference) from 0 to 1.&quot;&quot;&quot;</span>     
    <span class="k">while</span> <span class="n">cuda</span><span class="o">.</span><span class="n">atomic</span><span class="o">.</span><span class="n">compare_and_swap</span><span class="p">(</span><span class="n">mutex</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="n">cuda</span><span class="o">.</span><span class="n">threadfence</span><span class="p">()</span>    
    
<span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_unlock</span><span class="p">(</span><span class="n">mutex</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Device-side function that unlocks the wanted critical section (mutex mechanism). Unlocking means setting the value of variable or array cell (passed by reference) from 1 to 0.&quot;&quot;&quot;</span>
    <span class="n">cuda</span><span class="o">.</span><span class="n">threadfence</span><span class="p">()</span>
    <span class="n">cuda</span><span class="o">.</span><span class="n">atomic</span><span class="o">.</span><span class="n">exch</span><span class="p">(</span><span class="n">mutex</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>


<span class="c1"># the class</span>
<div class="viewcode-block" id="FastRealBoostBins"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins">[docs]</a><span class="k">class</span> <span class="nc">FastRealBoostBins</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An ensemble classifier for fast predictions implemented using numba.jit and numba.cuda. </span>
<span class="sd">    Bins with logit transform values play the role of &quot;weak learners&quot;.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        T (int): </span>
<span class="sd">            number of boosting rounds (equivalently, number of weak estimators), defaults to ``256``.            </span>
<span class="sd">        B (int): </span>
<span class="sd">            number of bins, defaults to ``8``.            </span>
<span class="sd">        outliers_ratio (float): </span>
<span class="sd">            fraction of outliers to skip (on each end) when establishing features’ variability ranges, defaults to ``0.05``.</span>
<span class="sd">        logit_max (np.float32):</span>
<span class="sd">            maximum absolute value of logit transform, outcomes clipped to interval [``-logit_max``, ``logit_max``], defaults to ``np.float32(2.0)``.</span>
<span class="sd">        fit_mode (str):</span>
<span class="sd">            choice of fit method from {``&quot;numpy&quot;``, ``&quot;numba_jit&quot;``, ``&quot;numba_cuda&quot;``}, defaults to ``&quot;numba_cuda&quot;``.</span>
<span class="sd">        decision_function_mode (str):</span>
<span class="sd">            choice of decision function method from {``&quot;numpy&quot;``, ``&quot;numba_jit&quot;``, ``&quot;numba_cuda&quot;``} (called e.g. within ``predict``), defaults to ``&quot;numba_cuda&quot;``.</span>
<span class="sd">        verbose (bool):</span>
<span class="sd">            verbosity flag, if ``True`` then fit progress and auxiliary information are printed to console, defaults to ``False``.</span>
<span class="sd">        debug_verbose (bool):</span>
<span class="sd">            detailed verbosity (only for ``&#39;numba_cuda&#39;`` fit), defaults to ``False``. </span>
<span class="sd">        </span>
<span class="sd">    Attributes:</span>
<span class="sd">        features_selected_ (ndarray[np.int32]):</span>
<span class="sd">            indexes of selected features, array of shape ``(T,)``.</span>
<span class="sd">        dtype_ (np.dtype): </span>
<span class="sd">            type of input data array, one of {``np.int8``, ``np.uint8``, ..., ``np.int64``, ``np.uint64``} or {``np.float32``, ``np.float64``} - numeric types only allowed.       </span>
<span class="sd">        mins_selected_ (ndarray[dtype_]): </span>
<span class="sd">            left ends of ranges for selected features, array of shape ``(T,)``.</span>
<span class="sd">        maxes_selected_ (ndarray[dtype_]):</span>
<span class="sd">            right ends of ranges for selected features, array of shape ``(T,)``.</span>
<span class="sd">        logits_ (ndarray[np.float32]): </span>
<span class="sd">            binned logit values for selected features, array of shape ``(T, B)``.            </span>
<span class="sd">        decision_function_numba_cuda_job_name_ (str): </span>
<span class="sd">            name, implied by ``dtype_``, of decision function to be called in case of ``&quot;numba_cuda&quot;`` mode (e.g. ``_decision_function_numba_cuda_job_int16``).</span>
<span class="sd">        decision_threshold_ (float): </span>
<span class="sd">            threshold value used inside ``predict`` function, defaults to ``0.0``.</span>
<span class="sd">        classes_ (ndarray): </span>
<span class="sd">            original class labels (scikit-learn requirement).</span>
<span class="sd">        n_features_in_ (int): </span>
<span class="sd">            number of features registered in ``fit`` call and expected for subsequent ``predict`` calls (scikit-learn requirement).            </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># constants</span>
    <span class="n">T_DEFAULT</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">B_DEFAULT</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">OUTLIERS_RATIO_DEFAULT</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">LOGIT_MAX_DEFAULT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="n">FIT_MODE_DEFAULT</span> <span class="o">=</span> <span class="s2">&quot;numba_cuda&quot;</span>
    <span class="n">DECISION_FUNCTION_MODE_DEFAULT</span> <span class="o">=</span> <span class="s2">&quot;numba_cuda&quot;</span>
    <span class="n">VERBOSE_DEFAULT</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">DEBUG_VERBOSE_DEFAULT</span> <span class="o">=</span> <span class="kc">False</span>
        
    <span class="n">B_MAX</span> <span class="o">=</span> <span class="mi">32</span>                    
    <span class="n">OUTLIERS_RATIO_MAX</span> <span class="o">=</span> <span class="mf">0.25</span>
    <span class="n">LOGIT_MAX_MAX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">8.0</span><span class="p">)</span>
    <span class="n">FIT_MODES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;numpy&quot;</span><span class="p">,</span> <span class="s2">&quot;numba_jit&quot;</span><span class="p">,</span> <span class="s2">&quot;numba_cuda&quot;</span><span class="p">]</span>
    <span class="n">DECISION_FUNCTION_MODES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;numpy&quot;</span><span class="p">,</span> <span class="s2">&quot;numba_jit&quot;</span><span class="p">,</span> <span class="s2">&quot;numba_cuda&quot;</span><span class="p">]</span>    
    <span class="n">CUDA_MAX_MEMORY_PER_CALL</span> <span class="o">=</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">2</span> <span class="c1"># applicable only for cuda-based fit, can be adjusted for given gpu device     </span>

    <span class="c1"># error messages</span>
    <span class="n">SKLEARN_ERR_MESSAGE_UNKNOWN_LABEL_TYPE</span> <span class="o">=</span> <span class="s2">&quot;Unknown label type&quot;</span>
    <span class="n">SKLEARN_ERR_MESSAGE_DISCREPANCY_IN_NO_OF_FEATURES</span> <span class="o">=</span> <span class="s2">&quot;Number of features in predict or decision_function is different from the number of features in fit&quot;</span>
    
<div class="viewcode-block" id="FastRealBoostBins.__init__"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T_DEFAULT</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="n">B_DEFAULT</span><span class="p">,</span> <span class="n">outliers_ratio</span><span class="o">=</span><span class="n">OUTLIERS_RATIO_DEFAULT</span><span class="p">,</span> <span class="n">logit_max</span><span class="o">=</span><span class="n">LOGIT_MAX_DEFAULT</span><span class="p">,</span> 
                 <span class="n">fit_mode</span><span class="o">=</span><span class="n">FIT_MODE_DEFAULT</span><span class="p">,</span> <span class="n">decision_function_mode</span><span class="o">=</span><span class="n">DECISION_FUNCTION_MODE_DEFAULT</span><span class="p">,</span> 
                 <span class="n">verbose</span><span class="o">=</span><span class="n">VERBOSE_DEFAULT</span><span class="p">,</span> <span class="n">debug_verbose</span><span class="o">=</span><span class="n">DEBUG_VERBOSE_DEFAULT</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor of ``FastRealBoostBins`` instances.</span>
<span class="sd">         </span>
<span class="sd">        Args:</span>
<span class="sd">            T (int): </span>
<span class="sd">                number of boosting rounds (equivalently, number of weak estimators), defaults to ``256``.            </span>
<span class="sd">            B (int): </span>
<span class="sd">                number of bins, defaults to ``8``.            </span>
<span class="sd">            outliers_ratio (float): </span>
<span class="sd">                fraction of outliers to skip (on each end) when establishing features’ variability ranges, defaults to ``0.05``.</span>
<span class="sd">            logit_max (np.float32):</span>
<span class="sd">                maximum absolute value of logit transform, outcomes clipped to interval [``-logit_max``, ``logit_max``], defaults to ``np.float32(2.0)``.</span>
<span class="sd">            fit_mode (str):</span>
<span class="sd">                choice of fit method from {``&quot;numpy&quot;``, ``&quot;numba_jit&quot;``, ``&quot;numba_cuda&quot;``}, defaults to ``&quot;numba_cuda&quot;``.</span>
<span class="sd">            decision_function_mode (str):</span>
<span class="sd">                choice of decision method from {``&quot;numpy&quot;``, ``&quot;numba_jit&quot;``, ``&quot;numba_cuda&quot;``} (called e.g. within ``predict``), defaults to ``&quot;numba_cuda&quot;``.</span>
<span class="sd">            verbose (bool):</span>
<span class="sd">                verbosity flag, if ``True`` then fit progress and auxiliary information are printed to console, defaults to ``False``.</span>
<span class="sd">            debug_verbose (bool):</span>
<span class="sd">                detailed verbosity (only for ``&#39;numba_cuda&#39;`` fit), defaults to ``False``.            </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">B</span>    
        <span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span> <span class="o">=</span> <span class="n">outliers_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span> <span class="o">=</span> <span class="n">logit_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span> <span class="o">=</span> <span class="n">fit_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span> <span class="o">=</span> <span class="n">decision_function_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span> <span class="o">=</span> <span class="n">debug_verbose</span>        </div>

<div class="viewcode-block" id="FastRealBoostBins._get_tags"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._get_tags">[docs]</a>    <span class="k">def</span> <span class="nf">_get_tags</span><span class="p">(</span><span class="bp">self</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns dictionary with particular properties of this estimator (compliant with scikit-learn guidelines).&quot;&quot;&quot;</span>
        <span class="n">tags</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_tags</span><span class="p">()</span>
        <span class="n">tags</span><span class="p">[</span><span class="s2">&quot;binary_only&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">tags</span><span class="p">[</span><span class="s2">&quot;non_deterministic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># in case of cuda computations  </span>
        <span class="k">return</span> <span class="n">tags</span></div>
    
<div class="viewcode-block" id="FastRealBoostBins.__str__"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.__str__">[docs]</a>    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns string representation of this classifier.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: string representation of this classifier.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(T=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">, B=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="si">}</span><span class="s2">, outliers_ratio=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span><span class="si">}</span><span class="s2">, logit_max: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="si">}</span><span class="s2">, fit_mode=&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span><span class="si">}</span><span class="s2">&#39;, decision_function_mode=&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span><span class="si">}</span><span class="s2">&#39;)&quot;</span></div>
            
<div class="viewcode-block" id="FastRealBoostBins.__repr__"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.__repr__">[docs]</a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns detailed string representation of this classifier.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: detailed string representation of this classifier.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">repr_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(T=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">, B=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="si">}</span><span class="s2">, outliers_ratio=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span><span class="si">}</span><span class="s2">, logit_max: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="si">}</span><span class="s2">, fit_mode=&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span><span class="si">}</span><span class="s2">&#39;, decision_function_mode=&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span><span class="si">}</span><span class="s2">&#39;,</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">repr_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;  verbose=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="si">}</span><span class="s2">, debug_verbose=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;classes_&quot;</span><span class="p">):</span>
            <span class="n">repr_str</span> <span class="o">+=</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span>                    
            <span class="n">repr_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;  classes_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="si">}</span><span class="s2">, dtype_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="si">}</span><span class="s2">, decision_function_numba_cuda_job_name_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_function_numba_cuda_job_name_</span><span class="si">}</span><span class="s2">, decision_threshold_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_threshold_</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">repr_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;  features_selected_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">repr_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;  mins_selected_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">repr_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;  maxes_selected_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">repr_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;  logits_=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">repr_str</span> <span class="o">+=</span> <span class="s2">&quot;)&quot;</span>
        <span class="k">return</span> <span class="n">repr_str</span></div>

<div class="viewcode-block" id="FastRealBoostBins._validate_param"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._validate_param">[docs]</a>    <span class="k">def</span> <span class="nf">_validate_param</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">ptype</span><span class="p">,</span> <span class="n">leq</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">geq</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">default</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validates a parameter - is it of correct type and within given range (either end of the range can be open or closed).&quot;&quot;&quot;</span>     
        <span class="n">invalid</span> <span class="o">=</span> <span class="n">value</span> <span class="o">&lt;=</span> <span class="n">low</span> <span class="k">if</span> <span class="n">leq</span> <span class="k">else</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="n">low</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">invalid</span><span class="p">:</span>
            <span class="n">invalid</span> <span class="o">=</span> <span class="n">value</span> <span class="o">&gt;=</span> <span class="n">high</span> <span class="k">if</span> <span class="n">geq</span> <span class="k">else</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">high</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">invalid</span><span class="p">:</span>
            <span class="n">invalid</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">ptype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">invalid</span><span class="p">:</span>
            <span class="n">correct_range_str</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;(&quot;</span> <span class="k">if</span> <span class="n">leq</span> <span class="k">else</span> <span class="s2">&quot;[&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">high</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;)&quot;</span> <span class="k">if</span> <span class="n">geq</span> <span class="k">else</span> <span class="s2">&quot;]&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[error -&gt; invalid param </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2"> changed to default: </span><span class="si">{</span><span class="n">default</span><span class="si">}</span><span class="s2">; correct range: </span><span class="si">{</span><span class="n">correct_range_str</span><span class="si">}</span><span class="s2">, correct type: </span><span class="si">{</span><span class="n">ptype</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">SKLEARN_ERR_MESSAGE_UNKNOWN_LABEL_TYPE</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="FastRealBoostBins._set_cuda_constants"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._set_cuda_constants">[docs]</a>    <span class="k">def</span> <span class="nf">_set_cuda_constants</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Investigates (via numba module) if CUDA-based computations are available and, if so, sets suitable constants.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_available</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_default</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">get_current_device</span><span class="p">()</span><span class="o">.</span><span class="n">MAX_THREADS_PER_BLOCK</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_available</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_bin_add_weights</span> <span class="o">=</span> <span class="mi">128</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_available</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">get_current_device</span><span class="p">()</span><span class="o">.</span><span class="n">ASYNC_ENGINE_COUNT</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_available</span> <span class="k">else</span> <span class="kc">None</span></div>
    
<div class="viewcode-block" id="FastRealBoostBins._set_modes"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._set_modes">[docs]</a>    <span class="k">def</span> <span class="nf">_set_modes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fit_mode</span><span class="o">=</span><span class="s2">&quot;numba_cuda&quot;</span><span class="p">,</span> <span class="n">decision_function_mode</span><span class="o">=</span><span class="s2">&quot;numba_cuda&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets modes for fit and decision_function functions.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">FIT_MODES</span><span class="p">:</span>
            <span class="n">invalid_mode</span> <span class="o">=</span> <span class="n">fit_mode</span>
            <span class="n">fit_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">FIT_MODE_DEFAULT</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[invalid fit mode: &#39;</span><span class="si">{</span><span class="n">invalid_mode</span><span class="si">}</span><span class="s2">&#39; changed to &#39;</span><span class="si">{</span><span class="n">fit_mode</span><span class="si">}</span><span class="s2">&#39;; possible modes: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">FIT_MODES</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">DECISION_FUNCTION_MODES</span><span class="p">:</span>
            <span class="n">invalid_mode</span> <span class="o">=</span> <span class="n">decision_function_mode</span>
            <span class="n">decision_function_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DECISION_FUNCTION_MODE_DEFAULT</span> 
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[invalid decision function mode: &#39;</span><span class="si">{</span><span class="n">invalid_mode</span><span class="si">}</span><span class="s2">&#39; changed to &#39;</span><span class="si">{</span><span class="n">decision_function_mode</span><span class="si">}</span><span class="s2">&#39;; possible modes: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">DECISION_FUNCTION_MODES</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span> <span class="o">=</span> <span class="n">fit_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span> <span class="o">=</span> <span class="n">decision_function_mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span> <span class="o">==</span> <span class="s2">&quot;numba_cuda&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_available</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span> <span class="o">=</span> <span class="s2">&quot;numba_jit&quot;</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[changing fit mode to &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span><span class="si">}</span><span class="s2">&#39; due to cuda functionality not available on this machine]&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span> <span class="o">==</span> <span class="s2">&quot;numba_cuda&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_available</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span> <span class="o">=</span> <span class="s1">&#39;numba_jit&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[changing decision function mode to &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span><span class="si">}</span><span class="s2">&#39; due to cuda functionality not available on this machine]&quot;</span><span class="p">)</span>       
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_fit_&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_decision_function_method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_decision_function_&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span><span class="p">)</span>                 </div>
                                                           
<div class="viewcode-block" id="FastRealBoostBins._logit"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._logit">[docs]</a>    <span class="k">def</span> <span class="nf">_logit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W_p</span><span class="p">,</span> <span class="n">W_n</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes a logit transform value based on sums of current boosting weights (for positive and negative examples) with proper clipping and handling of zeros in either numerator or denominator.&quot;&quot;&quot;</span>        
        <span class="k">if</span> <span class="n">W_p</span> <span class="o">==</span> <span class="n">W_n</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">W_p</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span>
        <span class="k">elif</span> <span class="n">W_n</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">W_p</span> <span class="o">/</span> <span class="n">W_n</span><span class="p">),</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="p">)</span></div>
                    
<div class="viewcode-block" id="FastRealBoostBins.fit"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the fit operation according to a general scheme of RealBoost algorithm (data reweighting, real-valued responses)</span>
<span class="sd">        and using an approach where bins with logit transform values play the role of &quot;weak learners&quot;. </span>
<span class="sd">        Each weak learner is based on one selected feature - the minimizer of exponential criterion (taking into account weights of data examples from a current boosting round).</span>
<span class="sd">        Computations are carried out according to the formerly chosen ``fit_mode`` i.e. one of {``&quot;numpy&quot;``, ``&quot;numba_jit&quot;``, ``&quot;numba_cuda&quot;``}.</span>
<span class="sd">        Depending on the mode, the function calls one of the following functions: ``_fit_numpy``, ``_fit_numba_jit``, or ``_fit_numba_cuda``.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): </span>
<span class="sd">                two-dimensional data array of numeric type with examples written as rows and features as columns.</span>
<span class="sd">            y (ndarray): </span>
<span class="sd">                one-dimensional array containing class labels associated with data examples.</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            self (FastRealBoostBins): </span>
<span class="sd">                reference to self (in compliance with scikit-learn guidelines).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># sklearn checks</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>                    
        <span class="n">check_classification_targets</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="c1"># actual functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_init</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_method</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>
        
<div class="viewcode-block" id="FastRealBoostBins._fit_init"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._fit_init">[docs]</a>    <span class="k">def</span> <span class="nf">_fit_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validates parameters and initializes some of the attributes and constants needed for actual fitting (taking into account information about the input data).&quot;&quot;&quot;</span>
        <span class="c1"># validation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">inf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_DEFAULT</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_MAX</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_DEFAULT</span><span class="p">)</span>    
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param</span><span class="p">(</span><span class="s2">&quot;outliers_ratio&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">OUTLIERS_RATIO_MAX</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">OUTLIERS_RATIO_DEFAULT</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param</span><span class="p">(</span><span class="s2">&quot;logit_max&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">LOGIT_MAX_MAX</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">LOGIT_MAX_DEFAULT</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param</span><span class="p">(</span><span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">VERBOSE_DEFAULT</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param</span><span class="p">(</span><span class="s2">&quot;debug_verbose&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEBUG_VERBOSE_DEFAULT</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_cuda_constants</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_modes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span><span class="p">)</span>
        <span class="c1"># initialization of attributes to be estimated (names with trailing underscores)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="c1"># indexes of selected features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># binned logits for selected features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decision_threshold_</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># default decision threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># unique class labels, we assume exactly 2 classes with first class negative</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span> <span class="c1"># dtype of input array </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_numba_cuda_job_name_</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_decision_function_numba_cuda_job_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="c1"># memorizing incoming number of features (same value expected later at predict stage according to sklearn)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>             </div>
    
<div class="viewcode-block" id="FastRealBoostBins._bin_data"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._bin_data">[docs]</a>    <span class="k">def</span> <span class="nf">_bin_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a binned version of data array using given variability ranges and knowing the number of bins. In binning arithmetics, suitably handles outliers and broadens data type (temporarily).&quot;&quot;&quot;</span>
        <span class="n">X_binned</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">spreads</span> <span class="o">=</span> <span class="n">maxes</span> <span class="o">-</span> <span class="n">mins</span>
        <span class="n">info</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span> 
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">)</span> <span class="o">*</span> <span class="n">spreads</span> <span class="o">&gt;</span> <span class="n">info</span><span class="o">.</span><span class="n">max</span><span class="p">):</span>
                <span class="n">broader_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int16</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">int16</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">:</span>
                    <span class="n">broader_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">:</span>
                    <span class="n">broader_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
                <span class="n">spreads</span><span class="p">[</span><span class="n">spreads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">max</span>                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">uint64</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[warning: temporarily changing dtype = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="si">}</span><span class="s2"> while binning to prevent overflow]&quot;</span><span class="p">)</span>
                    <span class="n">X_binned</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mins</span><span class="p">)</span> <span class="o">/</span> <span class="n">spreads</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>        
                <span class="k">else</span><span class="p">:</span>                    
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[warning: temporarily extending dtype = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">broader_dtype</span><span class="si">}</span><span class="s2"> while binning to prevent overflow]&quot;</span><span class="p">)</span>                 
                    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">broader_dtype</span><span class="p">)</span>
                    <span class="n">X_binned</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mins</span><span class="p">)</span> <span class="o">//</span> <span class="n">spreads</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>                 
                <span class="n">spreads</span><span class="p">[</span><span class="n">spreads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">max</span>
                <span class="n">X_binned</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mins</span><span class="p">)</span> <span class="o">//</span> <span class="n">spreads</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spreads</span><span class="p">[</span><span class="n">spreads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">max</span>
            <span class="n">X_binned</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mins</span><span class="p">)</span> <span class="o">/</span> <span class="n">spreads</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X_binned</span></div>

<div class="viewcode-block" id="FastRealBoostBins._find_ranges"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._find_ranges">[docs]</a>    <span class="k">def</span> <span class="nf">_find_ranges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finds and returns variability ranges after skipping a certain ratio of outliers on both ends.&quot;&quot;&quot;</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">mins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">maxes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">X_j_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">mins</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_j_sorted</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span> <span class="o">*</span> <span class="n">m</span><span class="p">))]</span>
                <span class="n">maxes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_j_sorted</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="n">m</span><span class="p">))]</span>
                <span class="k">if</span> <span class="n">mins</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">maxes</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                    <span class="n">mins</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_j_sorted</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">maxes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_j_sorted</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">maxes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span>        </div>
           
<div class="viewcode-block" id="FastRealBoostBins._fit_numpy"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._fit_numpy">[docs]</a>    <span class="k">def</span> <span class="nf">_fit_numpy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Performs the actual fit with computations carried out in ``&quot;numpy&quot;`` mode (the slowest one).&quot;&quot;&quot;</span> 
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FIT... [fit_numpy, X.shape: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, X.dtype=</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">, T: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">, B: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>        
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
        <span class="n">yy</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>        

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[finding ranges of features...]&quot;</span><span class="p">)</span>        
        <span class="n">t1_ranges</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_ranges</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">t2_ranges</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[finding ranges of features done; time: </span><span class="si">{</span><span class="n">t2_ranges</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_ranges</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[binning...]&quot;</span><span class="p">)</span>
        <span class="n">t1_binning</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">X_binned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bin_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span><span class="p">)</span>
        <span class="n">t2_binning</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[binning done; time: </span><span class="si">{</span><span class="n">t2_binning</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_binning</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>                
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[preparing indexing helpers...]&quot;</span><span class="p">)</span>
        <span class="n">t1_indexer</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">ind_p</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">ind_n</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">indexer_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">indexer_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span> 
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">):</span>
                <span class="n">j_in_b</span> <span class="o">=</span> <span class="n">X_binned</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">b</span>                    
                <span class="n">indexer_p</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">j_in_b</span><span class="p">,</span> <span class="n">ind_p</span><span class="p">)</span>
                <span class="n">indexer_n</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">j_in_b</span><span class="p">,</span> <span class="n">ind_n</span><span class="p">)</span>
        <span class="n">t2_indexer</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[preparing indexing helpers; time: </span><span class="si">{</span><span class="n">t2_indexer</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_indexer</span><span class="si">}</span><span class="s2"> s, shape: 2 x </span><span class="si">{</span><span class="n">indexer_p</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, size: 2 x </span><span class="si">{</span><span class="n">indexer_p</span><span class="o">.</span><span class="n">nbytes</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB]&quot;</span><span class="p">)</span>
                
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="c1"># boosting weights of data examples</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[main boosting loop...]&quot;</span><span class="p">)</span>
        <span class="n">t1_loop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">t1_round</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">...]&quot;</span><span class="p">)</span>
            <span class="n">best_err_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">best_j</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">W_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">W_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">logits_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">):</span>                                
                    <span class="n">W_p</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">indexer_p</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]])</span>
                    <span class="n">W_n</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">indexer_n</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]])</span>
                    <span class="n">logits_j</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logit</span><span class="p">(</span><span class="n">W_p</span><span class="p">[</span><span class="n">b</span><span class="p">],</span> <span class="n">W_n</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>
                <span class="n">err_exp_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">yy</span> <span class="o">*</span> <span class="n">logits_j</span><span class="p">[</span><span class="n">X_binned</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]]))</span>
                <span class="k">if</span> <span class="n">err_exp_j</span> <span class="o">&lt;</span> <span class="n">best_err_exp</span><span class="p">:</span>
                    <span class="n">best_err_exp</span> <span class="o">=</span> <span class="n">err_exp_j</span>
                    <span class="n">best_j</span> <span class="o">=</span> <span class="n">j</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">logits_j</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_j</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">yy</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">X_binned</span><span class="p">[:,</span> <span class="n">best_j</span><span class="p">]])</span> <span class="o">/</span> <span class="n">best_err_exp</span>
            <span class="n">t2_round</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2"> done; best_j: </span><span class="si">{</span><span class="n">best_j</span><span class="si">}</span><span class="s2">, best_err_exp: </span><span class="si">{</span><span class="n">best_err_exp</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">, best_logits: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="si">}</span><span class="s2">, time: </span><span class="si">{</span><span class="n">t2_round</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_round</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
        <span class="n">t2_loop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>        
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[main boosting loop done; time: </span><span class="si">{</span><span class="n">t2_loop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_loop</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span> <span class="o">=</span> <span class="n">mins</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span> <span class="o">=</span> <span class="n">maxes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
                
        <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FIT DONE. [fit_numpy; time: </span><span class="si">{</span><span class="n">t2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>    </div>
    
<div class="viewcode-block" id="FastRealBoostBins._fit_numba_jit"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._fit_numba_jit">[docs]</a>    <span class="k">def</span> <span class="nf">_fit_numba_jit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the actual fit with computations carried out in ``&quot;numba_jit&quot;`` mode.</span>
<span class="sd">        Inside the main boosting loop, all operations (weights binning, computing logits, computing exponential errors, finding the error minimizer, and examples reweighting)</span>
<span class="sd">        are perfomed  within a call to ``_fit_numba_jit_job`` function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FIT... [fit_numba_jit, X.shape: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, X.dtype=</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">, T: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">, B: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
        <span class="n">yy</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>        

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[finding ranges of features...]&quot;</span><span class="p">)</span>        
        <span class="n">t1_ranges</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_ranges</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>              
        <span class="n">t2_ranges</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[finding ranges of features done; time: </span><span class="si">{</span><span class="n">t2_ranges</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_ranges</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[binning...]&quot;</span><span class="p">)</span>
        <span class="n">t1_binning</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">X_binned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bin_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span><span class="p">)</span>
        <span class="n">t2_binning</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[binning done; time: </span><span class="si">{</span><span class="n">t2_binning</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_binning</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>                
                
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="c1"># boosting weights of data examples</span>
                
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[main boosting loop...]&quot;</span><span class="p">)</span>
        <span class="n">t1_loop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">t1_round</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">...]&quot;</span><span class="p">)</span>
            <span class="n">best_j</span><span class="p">,</span> <span class="n">best_err_exp</span><span class="p">,</span> <span class="n">best_logits</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_fit_numba_jit_job</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_j</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">best_logits</span><span class="p">)</span>            
            <span class="n">t2_round</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2"> done; best_j: </span><span class="si">{</span><span class="n">best_j</span><span class="si">}</span><span class="s2">, best_err_exp: </span><span class="si">{</span><span class="n">best_err_exp</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">, best_logits: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="si">}</span><span class="s2">, time: </span><span class="si">{</span><span class="n">t2_round</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_round</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
        <span class="n">t2_loop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>        
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[main boosting loop done; time: </span><span class="si">{</span><span class="n">t2_loop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_loop</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span> <span class="o">=</span> <span class="n">mins</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span> <span class="o">=</span> <span class="n">maxes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
                
        <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FIT DONE. [fit_numba_jit; time: </span><span class="si">{</span><span class="n">t2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="FastRealBoostBins._fit_numba_jit_job"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._fit_numba_jit_job">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="nd">@jit</span><span class="p">(</span><span class="n">nbtypes</span><span class="o">.</span><span class="n">Tuple</span><span class="p">((</span><span class="n">int32</span><span class="p">,</span> <span class="n">float32</span><span class="p">,</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:]))(</span><span class="n">int8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int8</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">int8</span><span class="p">,</span> <span class="n">float32</span><span class="p">),</span> <span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>    
    <span class="k">def</span> <span class="nf">_fit_numba_jit_job</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">logit_max</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the main boosting loop during fit carried out in ``&quot;numba_jit&quot;`` mode; called from within ``_fit_numba_jit`` function.&quot;&quot;&quot;</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X_binned</span><span class="o">.</span><span class="n">shape</span>           
        <span class="n">best_err_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
        <span class="n">best_j</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">best_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> 
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">W_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">W_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">logits_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">yy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">W_p</span><span class="p">[</span><span class="n">X_binned</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">W_n</span><span class="p">[</span><span class="n">X_binned</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
                <span class="n">W_p_b</span> <span class="o">=</span> <span class="n">W_p</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
                <span class="n">W_n_b</span> <span class="o">=</span> <span class="n">W_n</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>            
                <span class="n">logit_value</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">W_p_b</span> <span class="o">==</span> <span class="mf">0.0</span>  <span class="ow">and</span> <span class="n">W_n_b</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="n">logit_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">W_p_b</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">W_n_b</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">):</span>
                    <span class="n">logit_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">logit_max</span>
                <span class="k">elif</span> <span class="n">W_n_b</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">W_p_b</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">):</span>
                    <span class="n">logit_value</span> <span class="o">=</span> <span class="n">logit_max</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logit_value</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">W_p_b</span> <span class="o">/</span> <span class="n">W_n_b</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">logit_value</span> <span class="o">&gt;</span> <span class="n">logit_max</span><span class="p">:</span>
                        <span class="n">logit_value</span> <span class="o">=</span> <span class="n">logit_max</span>
                    <span class="k">elif</span> <span class="n">logit_value</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">logit_max</span><span class="p">:</span>
                        <span class="n">logit_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">logit_max</span>             
                <span class="n">logits_j</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">logit_value</span>
            <span class="n">err_exp_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">yy</span> <span class="o">*</span> <span class="n">logits_j</span><span class="p">[</span><span class="n">X_binned</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]]))</span>
            <span class="k">if</span> <span class="n">err_exp_j</span> <span class="o">&lt;</span> <span class="n">best_err_exp</span><span class="p">:</span>
                <span class="n">best_err_exp</span> <span class="o">=</span> <span class="n">err_exp_j</span>
                <span class="n">best_j</span> <span class="o">=</span> <span class="n">j</span>
                <span class="n">best_logits</span> <span class="o">=</span> <span class="n">logits_j</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">yy</span> <span class="o">*</span> <span class="n">best_logits</span><span class="p">[</span><span class="n">X_binned</span><span class="p">[:,</span> <span class="n">best_j</span><span class="p">]])</span> <span class="o">/</span> <span class="n">best_err_exp</span>
        <span class="k">return</span> <span class="n">best_j</span><span class="p">,</span> <span class="n">best_err_exp</span><span class="p">,</span> <span class="n">best_logits</span><span class="p">,</span> <span class="n">w</span> </div>
    
<div class="viewcode-block" id="FastRealBoostBins._prepare_cuda_call_ranges"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._prepare_cuda_call_ranges">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_prepare_cuda_call_ranges</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_calls_min</span><span class="p">,</span> <span class="n">power_two_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Prepares ranges of indexes (of data examples) for wanted number of subsequent calls for some CUDA kernel.&quot;&quot;&quot;</span>    
        <span class="k">if</span> <span class="n">n_calls_min</span> <span class="o">&gt;</span> <span class="n">m</span><span class="p">:</span>                
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[warning: wanted n_calls_min = </span><span class="si">{</span><span class="n">n_calls_min</span><span class="si">}</span><span class="s2"> greater than m = </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2"> in prepare_cuda_call_ranges(...); hence, setting n_calls_min to m]&quot;</span><span class="p">)</span>
            <span class="n">n_calls_min</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">power_two_sizes</span><span class="p">:</span>
            <span class="n">n_calls</span> <span class="o">=</span> <span class="n">n_calls_min</span>
            <span class="n">call_size</span> <span class="o">=</span> <span class="n">m</span> <span class="o">//</span> <span class="n">n_calls</span>
            <span class="n">call_ranges</span> <span class="o">=</span> <span class="n">call_size</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_calls</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>        
            <span class="n">call_ranges</span><span class="p">[:</span><span class="n">m</span> <span class="o">%</span> <span class="n">n_calls</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>      
        <span class="k">else</span><span class="p">:</span>
            <span class="n">call_size</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">n_calls_min</span><span class="p">))</span>
            <span class="n">n_calls</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">call_size</span><span class="p">))</span>
            <span class="n">call_ranges</span> <span class="o">=</span> <span class="n">call_size</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_calls</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">call_ranges</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span> <span class="o">%</span> <span class="n">call_size</span>
        <span class="n">call_ranges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">call_ranges</span><span class="p">)]</span>        
        <span class="k">return</span> <span class="n">n_calls</span><span class="p">,</span> <span class="n">call_ranges</span>                                            </div>
               
<div class="viewcode-block" id="FastRealBoostBins._fit_numba_cuda"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._fit_numba_cuda">[docs]</a>    <span class="k">def</span> <span class="nf">_fit_numba_cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the actual fit with computations carried out in ``&quot;numba_cuda&quot;`` mode.</span>
<span class="sd">        Inside the main boosting loop, all operations (weights binning, computing logits, computing exponential errors, finding the error minimizer, and examples reweighting)</span>
<span class="sd">        are perfomed, respectively, by the following CUDA kernel functions: ``_bin_add_weights_numba_cuda``, ``_logits_numba_cuda``, ``_errs_exp_numba_cuda``, ``_argmin_errs_exp_numba_cuda``, and ``_reweight_numba_cuda``.</span>
<span class="sd">        Three from those five kernels (1st, 3rd, 5th) are perfomed &quot;in chunks&quot;, i.e. for successive data slices, relying on CUDA streams mechanism (partial parallelization of computations and data transfers).        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FIT... [fit_numba_cuda, X.shape: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, X.dtype=</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">, T: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">, B: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
        <span class="n">yy</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>    
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[finding ranges of features...]&quot;</span><span class="p">)</span>
        <span class="n">t1_ranges</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_ranges</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">t2_ranges</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[finding ranges of features done; time: </span><span class="si">{</span><span class="n">t2_ranges</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_ranges</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>          
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[binning...]&quot;</span><span class="p">)</span>
        <span class="n">t1_binning</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>            
        <span class="n">X_binned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bin_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mins</span><span class="p">,</span> <span class="n">maxes</span><span class="p">)</span>        
        <span class="n">t2_binning</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[binning done; time: </span><span class="si">{</span><span class="n">t2_binning</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_binning</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>    
        
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="c1"># boosting weights of data examples</span>
        
        <span class="n">t1_loop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[main boosting loop...]&quot;</span><span class="p">)</span>                    
        <span class="n">dev_mutexes</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="c1"># in most cases per-feature mutexes  are applied (only in argmin case a single mutex)</span>
        <span class="n">dev_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">device_array</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>                                
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">t1_round</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2">...]&quot;</span><span class="p">)</span>
        
            <span class="n">t1_bin_add_weights</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>                        
            <span class="n">memory</span> <span class="o">=</span> <span class="n">X_binned</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">yy</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">w</span><span class="o">.</span><span class="n">nbytes</span> 
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">memory</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">CUDA_MAX_MEMORY_PER_CALL</span>
            <span class="k">if</span> <span class="n">ratio</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">n_calls</span><span class="p">,</span> <span class="n">call_ranges</span> <span class="o">=</span> <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_prepare_cuda_call_ranges</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ratio</span><span class="p">)))</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span><span class="p">,</span> <span class="n">n_calls</span><span class="p">)):</span>
                <span class="n">streams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">())</span>
            <span class="n">dev_W_p</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">dev_W_n</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">tpb</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_bin_add_weights</span>                          
            <span class="k">with</span> <span class="n">cuda</span><span class="o">.</span><span class="n">pinned</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_calls</span><span class="p">):</span>     
                    <span class="n">stream</span> <span class="o">=</span> <span class="n">streams</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span><span class="p">]</span>
                    <span class="n">call_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">call_ranges</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">call_ranges</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="n">X_binned_sub</span> <span class="o">=</span> <span class="n">X_binned</span><span class="p">[</span><span class="n">call_slice</span><span class="p">]</span>
                    <span class="n">dev_X_binned_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X_binned_sub</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">dev_yy_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">yy</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">dev_w_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">bpg</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">X_binned_sub</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">tpb</span><span class="p">)</span>
                    <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_bin_add_weights_numba_cuda</span><span class="p">[</span><span class="n">bpg</span><span class="p">,</span> <span class="n">tpb</span><span class="p">,</span> <span class="n">stream</span><span class="p">](</span><span class="n">dev_X_binned_sub</span><span class="p">,</span> <span class="n">dev_yy_sub</span><span class="p">,</span> <span class="n">dev_w_sub</span><span class="p">,</span> <span class="n">dev_W_p</span><span class="p">,</span> <span class="n">dev_W_n</span><span class="p">,</span> <span class="n">dev_mutexes</span><span class="p">)</span>
                <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">t2_bin_add_weights</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[bin_add_weights_numba_cuda done; n_calls: </span><span class="si">{</span><span class="n">n_calls</span><span class="si">}</span><span class="s2">; time: </span><span class="si">{</span><span class="n">t2_bin_add_weights</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_bin_add_weights</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>

            <span class="n">t1_logits</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>   
            <span class="n">tpb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span>
            <span class="n">bpg</span> <span class="o">=</span> <span class="n">n</span>
            <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_logits_numba_cuda</span><span class="p">[</span><span class="n">bpg</span><span class="p">,</span> <span class="n">tpb</span><span class="p">](</span><span class="n">dev_W_p</span><span class="p">,</span> <span class="n">dev_W_n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span><span class="p">,</span> <span class="n">dev_logits</span><span class="p">)</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">t2_logits</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[logits_numba_cuda done; time: </span><span class="si">{</span><span class="n">t2_logits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_logits</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>

            <span class="n">t1_errs_exp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>            
            <span class="n">memory</span> <span class="o">=</span> <span class="n">X_binned</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">yy</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">w</span><span class="o">.</span><span class="n">nbytes</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">memory</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">CUDA_MAX_MEMORY_PER_CALL</span>
            <span class="k">if</span> <span class="n">ratio</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">n_calls</span><span class="p">,</span> <span class="n">call_ranges</span> <span class="o">=</span> <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_prepare_cuda_call_ranges</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ratio</span><span class="p">)))</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>            
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span><span class="p">,</span> <span class="n">n_calls</span><span class="p">)):</span>
                <span class="n">streams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">())</span> 
            <span class="n">dev_errs_exp</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">tpb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_default</span>              
            <span class="k">with</span> <span class="n">cuda</span><span class="o">.</span><span class="n">pinned</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>                                
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_calls</span><span class="p">):</span>     
                    <span class="n">stream</span> <span class="o">=</span> <span class="n">streams</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span><span class="p">]</span>
                    <span class="n">call_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">call_ranges</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">call_ranges</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="n">X_binned_sub</span> <span class="o">=</span> <span class="n">X_binned</span><span class="p">[</span><span class="n">call_slice</span><span class="p">]</span>           
                    <span class="n">dev_X_binned_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X_binned_sub</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">dev_yy_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">yy</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">dev_w_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">bpg</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">X_binned_sub</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">tpb</span><span class="p">)</span>
                    <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_errs_exp_numba_cuda</span><span class="p">[</span><span class="n">bpg</span><span class="p">,</span> <span class="n">tpb</span><span class="p">,</span> <span class="n">stream</span><span class="p">](</span><span class="n">dev_X_binned_sub</span><span class="p">,</span> <span class="n">dev_yy_sub</span><span class="p">,</span> <span class="n">dev_w_sub</span><span class="p">,</span> <span class="n">dev_logits</span><span class="p">,</span> <span class="n">dev_errs_exp</span><span class="p">,</span> <span class="n">dev_mutexes</span><span class="p">)</span>
                <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">t2_errs_exp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[errs_exp_numba_cuda done; n_calls: </span><span class="si">{</span><span class="n">n_calls</span><span class="si">}</span><span class="s2">; time: </span><span class="si">{</span><span class="n">t2_errs_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_errs_exp</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>

            <span class="n">t1_argmin_errs_exp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>                                    
            <span class="n">best_err_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">best_j</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">best_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">dev_best_err_exp</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">best_err_exp</span><span class="p">)</span>
            <span class="n">dev_best_j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">best_j</span><span class="p">)</span>
            <span class="n">dev_best_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">best_logits</span><span class="p">)</span>
            <span class="n">tpb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_default</span>
            <span class="n">bpg</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">tpb</span>
            <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_argmin_errs_exp_numba_cuda</span><span class="p">[</span><span class="n">bpg</span><span class="p">,</span> <span class="n">tpb</span><span class="p">](</span><span class="n">dev_errs_exp</span><span class="p">,</span> <span class="n">dev_logits</span><span class="p">,</span> <span class="n">dev_best_err_exp</span><span class="p">,</span> <span class="n">dev_best_j</span><span class="p">,</span> <span class="n">dev_best_logits</span><span class="p">,</span> <span class="n">dev_mutexes</span><span class="p">)</span>
            <span class="n">dev_best_err_exp</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">ary</span><span class="o">=</span><span class="n">best_err_exp</span><span class="p">)</span>
            <span class="n">dev_best_j</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">ary</span><span class="o">=</span><span class="n">best_j</span><span class="p">)</span>
            <span class="n">dev_best_logits</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">ary</span><span class="o">=</span><span class="n">best_logits</span><span class="p">)</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_logits</span>
            <span class="n">t2_argmin_errs_exp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[argmin_errs_exp_numba_cuda done; time: </span><span class="si">{</span><span class="n">t2_argmin_errs_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_argmin_errs_exp</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>

            <span class="n">t1_reweight</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>                
            <span class="n">memory</span> <span class="o">=</span> <span class="n">X_binned</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">yy</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">w</span><span class="o">.</span><span class="n">nbytes</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">memory</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">CUDA_MAX_MEMORY_PER_CALL</span>
            <span class="k">if</span> <span class="n">ratio</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">n_calls</span><span class="p">,</span> <span class="n">call_ranges</span> <span class="o">=</span> <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_prepare_cuda_call_ranges</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ratio</span><span class="p">)))</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>            
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span><span class="p">,</span> <span class="n">n_calls</span><span class="p">)):</span>
                <span class="n">streams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">())</span>
            <span class="n">tpb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_default</span>      
            <span class="k">with</span> <span class="n">cuda</span><span class="o">.</span><span class="n">pinned</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_calls</span><span class="p">):</span>
                    <span class="n">stream</span> <span class="o">=</span> <span class="n">streams</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_n_streams</span><span class="p">]</span>
                    <span class="n">call_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">call_ranges</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">call_ranges</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="n">X_binned_sub</span> <span class="o">=</span> <span class="n">X_binned</span><span class="p">[</span><span class="n">call_slice</span><span class="p">]</span>           
                    <span class="n">dev_X_binned_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X_binned_sub</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">dev_yy_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">yy</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">dev_w_sub</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                    <span class="n">bpg</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_binned_sub</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">tpb</span>
                    <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_reweight_numba_cuda</span><span class="p">[</span><span class="n">bpg</span><span class="p">,</span> <span class="n">tpb</span><span class="p">,</span> <span class="n">stream</span><span class="p">](</span><span class="n">dev_X_binned_sub</span><span class="p">,</span> <span class="n">dev_yy_sub</span><span class="p">,</span> <span class="n">dev_w_sub</span><span class="p">,</span> <span class="n">dev_best_j</span><span class="p">,</span> <span class="n">dev_best_err_exp</span><span class="p">,</span> <span class="n">dev_best_logits</span><span class="p">)</span>
                    <span class="n">dev_w_sub</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">ary</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="n">call_slice</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
                <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">t2_reweight</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[reweight_numba_cuda done; n_calls: </span><span class="si">{</span><span class="n">n_calls</span><span class="si">}</span><span class="s2">; time: </span><span class="si">{</span><span class="n">t2_reweight</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_reweight</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
            <span class="n">t2_round</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="si">}</span><span class="s2"> done; best_j: </span><span class="si">{</span><span class="n">best_j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, best_err_exp: </span><span class="si">{</span><span class="n">best_err_exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">, best_logits: </span><span class="si">{</span><span class="n">best_logits</span><span class="si">}</span><span class="s2">, time: </span><span class="si">{</span><span class="n">t2_round</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_round</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>
                        
        <span class="n">t2_loop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[main boosting loop done; time: </span><span class="si">{</span><span class="n">t2_loop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_loop</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span> <span class="o">=</span> <span class="n">mins</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span> <span class="o">=</span> <span class="n">maxes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        
        <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FIT DONE. [fit_numba_cuda; time: </span><span class="si">{</span><span class="n">t2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>      </div>
                
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int8</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int32</span><span class="p">[:,</span> <span class="p">:]))</span>    
    <span class="k">def</span> <span class="nf">_bin_add_weights_numba_cuda</span><span class="p">(</span><span class="n">X_binned_sub</span><span class="p">,</span> <span class="n">yy_sub</span><span class="p">,</span> <span class="n">w_sub</span><span class="p">,</span> <span class="n">W_p</span><span class="p">,</span> <span class="n">W_n</span><span class="p">,</span> <span class="n">mutexes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;CUDA kernel responsible for binning and adding weights (within the main boosting loop).&quot;&quot;&quot;</span>         
        <span class="n">shared_w_p</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># assumed max constants for shared memory: 128 - subsample size (equal to self._cuda_tpb_bin_add_weights), 32 - no. of bins</span>
        <span class="n">shared_w_n</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> 
        <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X_binned_sub</span><span class="o">.</span><span class="n">shape</span>        
        <span class="n">j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">tpb</span> <span class="o">+</span> <span class="n">tx</span> <span class="c1"># local data point index within current data sub (not global)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">W_p</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">b_i_j</span> <span class="o">=</span> <span class="n">X_binned_sub</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">b_i_j</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="n">b_i_j</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">yy_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">shared_w_p</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="n">shared_w_n</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">shared_w_p</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                    <span class="n">shared_w_n</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>                    
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shared_w_p</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="n">shared_w_n</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
                    <span class="n">shared_w_p</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_w_p</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
                    <span class="n">shared_w_n</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_w_n</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>           
            <span class="n">_lock</span><span class="p">(</span><span class="n">mutexes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> 
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>                                 
                <span class="n">W_p</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_w_p</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
                <span class="n">W_n</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_w_n</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>                                     
            <span class="n">_unlock</span><span class="p">(</span><span class="n">mutexes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">,</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:]))</span>
    <span class="k">def</span> <span class="nf">_logits_numba_cuda</span><span class="p">(</span><span class="n">W_p</span><span class="p">,</span> <span class="n">W_n</span><span class="p">,</span> <span class="n">logit_max</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;CUDA kernel responsible for computing binned logit values (within the main boosting loop).&quot;&quot;&quot;</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">W_p_j_b</span> <span class="o">=</span> <span class="n">W_p</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
        <span class="n">W_n_j_b</span> <span class="o">=</span> <span class="n">W_n</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> 
        <span class="k">if</span> <span class="n">W_p_j_b</span> <span class="o">==</span> <span class="n">W_n_j_b</span><span class="p">:</span>
            <span class="n">logits</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">W_p_j_b</span> <span class="o">==</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">):</span>
            <span class="n">logits</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">logit_max</span>
        <span class="k">elif</span> <span class="n">W_n_j_b</span> <span class="o">==</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">):</span>
            <span class="n">logits</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">logit_max</span> <span class="c1"># equal to +LOGIT_MAX</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">W_p_j_b</span> <span class="o">/</span> <span class="n">W_n_j_b</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">temp</span> <span class="o">&gt;</span> <span class="n">logit_max</span><span class="p">:</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">logit_max</span>
            <span class="k">elif</span> <span class="n">temp</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">logit_max</span><span class="p">:</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="o">-</span><span class="n">logit_max</span>
            <span class="n">logits</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>                          

    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int8</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">int32</span><span class="p">[:,</span> <span class="p">:]))</span>
    <span class="k">def</span> <span class="nf">_errs_exp_numba_cuda</span><span class="p">(</span><span class="n">X_binned_sub</span><span class="p">,</span> <span class="n">yy_sub</span><span class="p">,</span> <span class="n">w_sub</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">errs_exp</span><span class="p">,</span> <span class="n">mutexes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;CUDA kernel responsible for computing exponential errors (within the main boosting loop).&quot;&quot;&quot;</span>
        <span class="n">shared_errs_exp</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">512</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># assumed max constant: 512 - subsample size                </span>
        <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X_binned_sub</span><span class="o">.</span><span class="n">shape</span>                                                
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">tpb</span> <span class="o">+</span> <span class="n">tx</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">w_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">yy_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">logits</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">X_binned_sub</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">err</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>   
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">_lock</span><span class="p">(</span><span class="n">mutexes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            <span class="n">errs_exp</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">_unlock</span><span class="p">(</span><span class="n">mutexes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">int32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">int32</span><span class="p">[:,</span> <span class="p">:]))</span>
    <span class="k">def</span> <span class="nf">_argmin_errs_exp_numba_cuda</span><span class="p">(</span><span class="n">errs_exp</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">best_err_exp</span><span class="p">,</span> <span class="n">best_j</span><span class="p">,</span> <span class="n">best_logits</span><span class="p">,</span> <span class="n">mutexes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;CUDA kernel responsible for finding the error minimizer (within the main boosting loop).&quot;&quot;&quot;</span>
        <span class="n">shared_errs_exp</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">512</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># assumed max tpb</span>
        <span class="n">shared_best_j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">512</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span> <span class="c1"># assumed max tpb</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">errs_exp</span><span class="o">.</span><span class="n">size</span>                
        <span class="n">j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">errs_exp</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">shared_best_j</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="n">inf</span><span class="p">)</span>
            <span class="n">shared_best_j</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">int32</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">tx_stride</span> <span class="o">=</span> <span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span>
                <span class="k">if</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx_stride</span><span class="p">]:</span>
                    <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="n">tx_stride</span><span class="p">]</span>
                    <span class="n">shared_best_j</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_best_j</span><span class="p">[</span><span class="n">tx_stride</span><span class="p">]</span>                
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>            
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">_lock</span><span class="p">(</span><span class="n">mutexes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_err_exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">best_err_exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_errs_exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">the_best_j</span> <span class="o">=</span> <span class="n">shared_best_j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">best_j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">the_best_j</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">best_logits</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
                    <span class="n">best_logits</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">the_best_j</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">_unlock</span><span class="p">(</span><span class="n">mutexes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int8</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">int32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_reweight_numba_cuda</span><span class="p">(</span><span class="n">X_binned_sub</span><span class="p">,</span> <span class="n">yy_sub</span><span class="p">,</span> <span class="n">w_sub</span><span class="p">,</span> <span class="n">best_j</span><span class="p">,</span> <span class="n">best_exp_err</span><span class="p">,</span> <span class="n">best_logits</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;CUDA kernel responsible for reweighting data examples (within the main boosting loop).&quot;&quot;&quot;</span>           
        <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X_binned_sub</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>        
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">w_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">yy_sub</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">best_logits</span><span class="p">[</span><span class="n">X_binned_sub</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">best_j</span><span class="p">[</span><span class="mi">0</span><span class="p">]]])</span> <span class="o">/</span> <span class="n">best_exp_err</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="FastRealBoostBins.decrease_T"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.decrease_T">[docs]</a>    <span class="k">def</span> <span class="nf">decrease_T</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decreases the number of weak estimators in this ensemble classifier. Attention: can be used only when the classifier has been fit (after ``fit`` function was called).</span>
<span class="sd">        Plays the role of a utility allowing one to easily reduce the classifier (e.g. to check accuracy of the smaller one) without having to refit it for a smaller ``T`` value.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            T (int): </span>
<span class="sd">                new wanted number weak estimators.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">[:</span><span class="n">T</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[:</span><span class="n">T</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span><span class="p">[:</span><span class="n">T</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span><span class="p">[:</span><span class="n">T</span><span class="p">]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span></div>

<div class="viewcode-block" id="FastRealBoostBins.decision_function"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.decision_function">[docs]</a>    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes real-valued responses of ensemble for given data array.</span>
<span class="sd">        Depending on the mode, delegates actual computations to one of the following functions: ``_decision_function_numpy``, ``_decision_function_numba_jit``, or ``_decision_function_numba_cuda``.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            X (ndarray[dtype_]):</span>
<span class="sd">                two-dimensional data array of numeric type with examples written as rows and features as columns (must have the same number of features as registered at fit stage).</span>
<span class="sd">                </span>
<span class="sd">        Returns:</span>
<span class="sd">            responses (ndarray[np.float32]): </span>
<span class="sd">                one-dimensional array of ensemble responses. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># sklearn checks</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">SKLEARN_ERR_MESSAGE_DISCREPANCY_IN_NO_OF_FEATURES</span><span class="p">)</span>        
        <span class="c1"># actual function        </span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decision_function_method</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>
        
<div class="viewcode-block" id="FastRealBoostBins._decision_function_numpy"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._decision_function_numpy">[docs]</a>    <span class="k">def</span> <span class="nf">_decision_function_numpy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Performs the actual decision function with computations carried out in ``&quot;numpy&quot;`` mode (the slowest one).&quot;&quot;&quot;</span>
        <span class="n">X_selected</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        <span class="n">X_binned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bin_data</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">X_binned</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">X_binned</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>     
        <span class="k">return</span> <span class="n">responses</span></div>

<div class="viewcode-block" id="FastRealBoostBins._decision_function_numba_jit"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._decision_function_numba_jit">[docs]</a>    <span class="k">def</span> <span class="nf">_decision_function_numba_jit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Performs the actual decision function with computations carried out in ``&quot;numba_jit&quot;`` mode.&quot;&quot;&quot;</span>
        <span class="n">X_selected</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        <span class="n">X_binned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bin_data</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span><span class="p">)</span>        
        <span class="k">return</span> <span class="n">FastRealBoostBins</span><span class="o">.</span><span class="n">_decision_function_numba_jit_job</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="FastRealBoostBins._decision_function_numba_jit_job"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._decision_function_numba_jit_job">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="nd">@jit</span><span class="p">(</span><span class="n">float32</span><span class="p">[:](</span><span class="n">int8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:]),</span> <span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_jit_job</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_jit&quot;`` mode; called from within ``_decision_function_numba_jit`` function.&quot;&quot;&quot;</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">X_binned</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>  
                <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">X_binned</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]]</span>
        <span class="k">return</span> <span class="n">responses</span></div>
    
<div class="viewcode-block" id="FastRealBoostBins._decision_function_numba_cuda"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins._decision_function_numba_cuda">[docs]</a>    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the actual decision function with computations carried out in ``&quot;numba_cuda&quot;`` mode.</span>
<span class="sd">        Depending on the type of input data array, delegates actual computations to one of the following kernel functions: </span>
<span class="sd">        ``_decision_function_numba_cuda_job_int8``, ``_decision_function_numba_cuda_job_uint8``, ..., ``_decision_function_numba_cuda_job_int64``, ``_decision_function_numba_cuda_job_uint64``,</span>
<span class="sd">        or ``_decision_function_numba_cuda_job_float32``, ``_decision_function_numba_cuda_job_float64``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_selected</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="p">]</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">X_selected</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dev_X_selected</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X_selected</span><span class="p">)</span>
        <span class="n">dev_mins_selected</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span><span class="p">)</span>
        <span class="n">dev_maxes_selected</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span><span class="p">)</span>
        <span class="n">dev_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="p">)</span>                
        <span class="n">dev_responses</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">device_array</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cuda_tpb_default</span>
        <span class="n">bpg</span> <span class="o">=</span> <span class="n">m</span>    
        <span class="n">decision_function_numba_cuda_job_method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">FastRealBoostBins</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_numba_cuda_job_name_</span><span class="p">)</span>
        <span class="n">decision_function_numba_cuda_job_method</span><span class="p">[</span><span class="n">bpg</span><span class="p">,</span> <span class="n">tpb</span><span class="p">](</span><span class="n">dev_X_selected</span><span class="p">,</span> <span class="n">dev_mins_selected</span><span class="p">,</span> <span class="n">dev_maxes_selected</span><span class="p">,</span> <span class="n">dev_logits</span><span class="p">,</span> <span class="n">dev_responses</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">dev_responses</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">()</span>        
        <span class="k">return</span> <span class="n">responses</span></div>

    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int8</span><span class="p">[:],</span> <span class="n">int8</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_int8</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``int8``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed later if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">int16</span><span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int16</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="o">//</span> <span class="p">(</span><span class="n">int16</span><span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int16</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])))</span>                
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">uint8</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">uint8</span><span class="p">[:],</span> <span class="n">uint8</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_uint8</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``uint8``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">int16</span><span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int16</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="o">//</span> <span class="p">(</span><span class="n">int16</span><span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int16</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    
    
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int16</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int16</span><span class="p">[:],</span> <span class="n">int16</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_int16</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``int16``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">int32</span><span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int32</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="o">//</span> <span class="p">(</span><span class="n">int32</span><span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int32</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])))</span>                
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">uint16</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">uint16</span><span class="p">[:],</span> <span class="n">uint16</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_uint16</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``uint16``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">int32</span><span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int32</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="o">//</span> <span class="p">(</span><span class="n">int32</span><span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int32</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>            
            
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int32</span><span class="p">[:],</span> <span class="n">int32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_int32</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``int32``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">int64</span><span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int64</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="o">//</span> <span class="p">(</span><span class="n">int64</span><span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int64</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>            

    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">uint32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">uint32</span><span class="p">[:],</span> <span class="n">uint32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_uint32</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``uint32``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">int64</span><span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int64</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="o">//</span> <span class="p">(</span><span class="n">int64</span><span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">-</span> <span class="n">int64</span><span class="p">(</span><span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">int64</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">int64</span><span class="p">[:],</span> <span class="n">int64</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_int64</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``int64``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">//</span> <span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">uint64</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">uint64</span><span class="p">[:],</span> <span class="n">uint64</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_uint64</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Body of the decision function carried out in ``&quot;numba_cuda&quot;`` mode suitable for input arrays of type ``uint32``; called from within ``_decision_function_numba_cuda`` function.&quot;&quot;&quot;</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">//</span> <span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>            
            
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_float32</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>            
            
    <span class="nd">@staticmethod</span>
    <span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">void</span><span class="p">(</span><span class="n">float64</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float64</span><span class="p">[:],</span> <span class="n">float64</span><span class="p">[:],</span> <span class="n">float32</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">float32</span><span class="p">[:]))</span>
    <span class="k">def</span> <span class="nf">_decision_function_numba_cuda_job_float64</span><span class="p">(</span><span class="n">X_selected</span><span class="p">,</span> <span class="n">mins_selected</span><span class="p">,</span> <span class="n">maxes_selected</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
        <span class="n">shared_logits</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1024 - corresponds to assumed max tpb           </span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tpb</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
        <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">fpt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="n">tpb</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">tpb</span><span class="p">)</span> <span class="c1"># features per thread to be translated onto appropriate logits and stored in shared memory (summed if fpt &gt; 1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tx</span> <span class="c1"># feature index</span>
        <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fpt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">int8</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_selected</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">maxes_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">mins_selected</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
                <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">elif</span> <span class="n">b</span> <span class="o">&gt;=</span> <span class="n">B</span><span class="p">:</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">logits</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">tpb</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">tpb</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span> <span class="c1"># half of tpb</span>
        <span class="k">while</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># sum-reduction pattern</span>
            <span class="k">if</span> <span class="n">tx</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">:</span>
                <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">stride</span><span class="p">]</span>
            <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>            
         
<div class="viewcode-block" id="FastRealBoostBins.predict"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns class labels predicted for given data array.</span>
<span class="sd">        Delegates actual computations to ``decision_function`` and maps real-valued responses obtained from it to one of two class labels (negative or positive) kept in ``self.classes_``, </span>
<span class="sd">        taking into account the ``self.decision_threshold_`` attribute.   </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            X (ndarray[dtype_]):</span>
<span class="sd">                two-dimensional data array of numeric type with examples written as rows and features as columns (must have the same number of features as registered at fit stage).</span>
<span class="sd">                </span>
<span class="sd">        Returns:</span>
<span class="sd">            class labels (ndarray): </span>
<span class="sd">                one-dimensional array of predicted class labels. </span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_threshold_</span><span class="p">)]</span></div>
    
<div class="viewcode-block" id="FastRealBoostBins.json_dump"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.json_dump">[docs]</a>    <span class="k">def</span> <span class="nf">json_dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dumps (saves) this ensemble classifier to a text file in json format.   </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            fname (string):</span>
<span class="sd">                file name.             </span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JSON DUMP... [to file: </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>        
        <span class="n">d</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;B&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;outliers_ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outliers_ratio</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;logit_max&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_max</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;fit_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_mode</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;decision_function_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_mode</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;debug_verbose&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;classes_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;n_features_in_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;dtype_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>            
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;decision_function_numba_cuda_job_name_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function_numba_cuda_job_name_</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;decision_threshold_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_threshold_</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;features_selected_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_selected_</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;mins_selected_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mins_selected_</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;maxes_selected_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxes_selected_</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">d</span><span class="p">[</span><span class="s2">&quot;logits_&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">&quot;w+&quot;</span><span class="p">)</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">IOError</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[error occurred when trying to dump clf as json to file: </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JSON DUMP DONE. [time: </span><span class="si">{</span><span class="n">t2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span></div>
            
<div class="viewcode-block" id="FastRealBoostBins.json_load"><a class="viewcode-back" href="../frbb.html#frbb.FastRealBoostBins.json_load">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">json_load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>        
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates and returns an instance of ``FastRealBoostBins`` from a text file in json format given its file path.   </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            fname (string):</span>
<span class="sd">                file name.</span>
<span class="sd">            verbose (bool):</span>
<span class="sd">                verbosity flag.        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JSON LOAD... [from file: </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;B&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;B&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;outliers_ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;outliers_ratio&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;logit_max&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;logit_max&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;fit_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;fit_mode&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;decision_function_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;decision_function_mode&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;debug_verbose&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;debug_verbose&quot;</span><span class="p">]</span>                            
            <span class="n">clf</span> <span class="o">=</span> <span class="n">FastRealBoostBins</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">_set_cuda_constants</span><span class="p">()</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">_set_modes</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">fit_mode</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function_mode</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;classes_&quot;</span><span class="p">])</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;n_features_in_&quot;</span><span class="p">]</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;dtype_&quot;</span><span class="p">]</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">decision_function_numba_cuda_job_name_</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;decision_function_numba_cuda_job_name_&quot;</span><span class="p">]</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">decision_threshold_</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;decision_threshold_&quot;</span><span class="p">]</span>            
            <span class="n">clf</span><span class="o">.</span><span class="n">features_selected_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;features_selected_&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">mins_selected_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;mins_selected_&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">maxes_selected_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;maxes_selected_&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">logits_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;logits_&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">IOError</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[error occurred when trying to load clf from json file: </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JSON LOAD DONE. [time: </span><span class="si">{</span><span class="n">t2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1</span><span class="si">}</span><span class="s2"> s]&quot;</span><span class="p">)</span>    
        <span class="k">return</span> <span class="n">clf</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Przemysław Klęsk.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>